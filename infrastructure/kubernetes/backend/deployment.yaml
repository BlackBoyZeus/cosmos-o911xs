# Kubernetes deployment configuration for Cosmos WFM Platform backend services
# Base image: nvidia/cuda:12.0-base-ubuntu22.04
# Kubernetes version: 1.24+

apiVersion: apps/v1
kind: Deployment
metadata:
  name: cosmos-backend
  namespace: cosmos-wfm
  labels:
    app: cosmos-backend
    component: api
    part-of: cosmos-platform
    version: latest
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: cosmos-backend
  template:
    metadata:
      labels:
        app: cosmos-backend
        security-context: restricted
      annotations:
        # Prometheus monitoring configuration
        prometheus.io/scrape: "true"
        prometheus.io/port: "3000"
        prometheus.io/path: "/metrics"
        # Security profile configurations
        seccomp.security.alpha.kubernetes.io/pod: "runtime/default"
        container.apparmor.security.beta.kubernetes.io/cosmos-backend: "runtime/default"
    spec:
      containers:
      - name: cosmos-backend
        image: cosmos-backend:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 3000
          protocol: TCP
          name: http
        resources:
          requests:
            cpu: "4"
            memory: "16Gi"
            nvidia.com/gpu: "1"
            nvidia.com/gpu-memory: "32Gi"
          limits:
            cpu: "8"
            memory: "32Gi"
            nvidia.com/gpu: "1"
            nvidia.com/gpu-memory: "64Gi"
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          runAsGroup: 1000
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: model-cache
          mountPath: /cache
      volumes:
      - name: tmp
        emptyDir: {}
      - name: model-cache
        emptyDir:
          medium: Memory
          sizeLimit: "32Gi"
      # Topology spread constraints for high availability
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: cosmos-backend
      # Node affinity for GPU scheduling
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu
                operator: Exists
              - key: cloud.google.com/gke-accelerator
                operator: In
                values:
                - nvidia-tesla-a100