# Kubernetes HPA configuration for Cosmos WFM Platform backend services
# Version: v1.27+
# Purpose: Automatic scaling of backend pods based on CPU, memory and GPU utilization

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: cosmos-backend-hpa
  namespace: cosmos-wfm
  labels:
    app: cosmos-backend
    component: api
    part-of: cosmos-platform
spec:
  # Target the backend deployment for scaling
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: cosmos-backend

  # Maintain between 3-10 replicas for high availability
  minReplicas: 3
  maxReplicas: 10

  # Scaling metrics
  metrics:
    # CPU utilization target of 80%
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 80

    # Memory utilization target of 85%
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 85

    # Custom GPU utilization metric from Prometheus
    - type: Pods
      pods:
        metric:
          name: gpu_utilization
        target:
          type: AverageValue
          averageValue: "85"

  # Scaling behavior configuration
  behavior:
    # Scale up configuration
    scaleUp:
      # Wait 60s before scaling up to avoid thrashing
      stabilizationWindowSeconds: 60
      policies:
        # Add up to 2 pods every 60 seconds
        - type: Pods
          value: 2
          periodSeconds: 60

    # Scale down configuration
    scaleDown:
      # Wait 5 minutes before scaling down to ensure load decrease is sustained
      stabilizationWindowSeconds: 300
      policies:
        # Remove 1 pod every 2 minutes
        - type: Pods
          value: 1
          periodSeconds: 120